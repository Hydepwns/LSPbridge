#!/bin/bash
# Test script for benchmark dashboard
# Runs a quick local test of the benchmark system

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(cd "${SCRIPT_DIR}/.." && pwd)"

# Colors
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[TEST] $*${NC}"
}

success() {
    echo -e "${GREEN}[SUCCESS] $*${NC}"
}

warn() {
    echo -e "${YELLOW}[INFO] $*${NC}"
}

main() {
    log "Testing LSPbridge Benchmark Dashboard"
    
    cd "${PROJECT_DIR}"
    
    log "1. Checking dependencies..."
    if ! command -v cargo >/dev/null 2>&1; then
        echo "Error: cargo not found. Install Rust first."
        exit 1
    fi
    
    log "2. Running a quick benchmark subset..."
    # Run just the lightweight benchmarks for testing
    timeout 60s cargo bench -- --quick || {
        warn "Full benchmarks timed out, this is expected for testing"
    }
    
    log "3. Testing benchmark dashboard script..."
    if [[ -x "${SCRIPT_DIR}/benchmark-dashboard.sh" ]]; then
        # Run setup only for testing
        "${SCRIPT_DIR}/benchmark-dashboard.sh" setup
        success "Dashboard script is executable and setup works"
    else
        echo "Error: benchmark-dashboard.sh not found or not executable"
        exit 1
    fi
    
    log "4. Testing visualization script..."
    if command -v python3 >/dev/null 2>&1; then
        if [[ -x "${SCRIPT_DIR}/generate_benchmark_charts.py" ]]; then
            # Test the visualization script imports
            python3 -c "
import sys
sys.path.insert(0, '${SCRIPT_DIR}')
try:
    exec(open('${SCRIPT_DIR}/generate_benchmark_charts.py').read())
    print('âœ“ Visualization script loads successfully')
except ImportError as e:
    print(f'âš  Some visualization libraries missing: {e}')
except SystemExit:
    pass  # Expected when no data directory exists
except Exception as e:
    print(f'âœ— Error in visualization script: {e}')
    sys.exit(1)
            "
            success "Visualization script is functional"
        else
            warn "Visualization script not found or not executable"
        fi
    else
        warn "Python3 not available for testing visualization"
    fi
    
    log "5. Checking configuration..."
    if [[ -f "${PROJECT_DIR}/benchmark-config.toml" ]]; then
        success "Benchmark configuration file exists"
    else
        warn "Benchmark configuration file not found"
    fi
    
    log "6. Testing CI workflow syntax..."
    if [[ -f "${PROJECT_DIR}/.github/workflows/ci.yml" ]]; then
        success "CI workflow file exists"
    else
        warn "CI workflow file not found"
    fi
    
    success "Benchmark dashboard test completed successfully!"
    echo ""
    echo "ðŸ“‹ Next steps:"
    echo "  1. Run 'cargo bench' to generate full benchmark data"
    echo "  2. Run './scripts/benchmark-dashboard.sh run' to generate dashboard"
    echo "  3. Check benchmark-results/reports/ for generated reports"
    echo "  4. Commit changes and push to trigger CI benchmarks"
    echo ""
}

main "$@"