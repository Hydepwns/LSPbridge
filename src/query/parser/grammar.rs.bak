//! Grammar rules and parsing logic for the query language

use super::ast::*;
use super::lexer::{Token, TokenType};
use crate::core::errors::ParseError;
use crate::core::DiagnosticSeverity;
use chrono::{DateTime, Utc};
use std::str::FromStr;

/// Recursive descent parser for the query language
pub struct Parser {
    tokens: Vec<Token>,
    current: usize,
}

impl Parser {
    /// Create a new parser with the given tokens
    pub fn new(tokens: Vec<Token>) -> Self {
        Self { tokens, current: 0 }
    }

    /// Parse the tokens into a Query AST
    pub fn parse(&mut self) -> Result<Query, ParseError> {
        self.query()
    }

    /// Parse a complete query
    /// query = select_clause from_clause where_clause? group_by_clause? order_by_clause? limit_clause?
    fn query(&mut self) -> Result<Query, ParseError> {
        let select = self.select_clause()?;
        let from = self.from_clause()?;
        
        let mut filters = Vec::new();
        let mut time_range = None;
        
        // Optional WHERE clause
        if self.match_token(&TokenType::Where) {
            let (parsed_filters, parsed_time_range) = self.where_clause()?;
            filters = parsed_filters;
            time_range = parsed_time_range;
        }
        
        // Optional GROUP BY clause
        let group_by = if self.match_token(&TokenType::GroupBy) {
            Some(self.group_by_clause()?)
        } else {
            None
        };
        
        // Optional ORDER BY clause
        let order_by = if self.match_token(&TokenType::OrderBy) {
            Some(self.order_by_clause()?)
        } else {
            None
        };
        
        // Optional LIMIT clause
        let limit = if self.match_token(&TokenType::Limit) {
            Some(self.limit_clause()?)
        } else {
            None
        };

        Ok(Query {
            select,
            from,
            filters,
            group_by,
            order_by,
            limit,
            time_range,
        })
    }

    /// Parse SELECT clause
    /// select_clause = "SELECT" ("*" | "COUNT" "(" "*" ")" | field_list | aggregation_list)
    fn select_clause(&mut self) -> Result<SelectClause, ParseError> {
        self.consume(&TokenType::Select, "Expected 'SELECT'")?;

        if self.check(&TokenType::Asterisk) {
            self.advance();
            Ok(SelectClause::All)
        } else if self.check(&TokenType::Count) {
            self.advance();
            self.consume(&TokenType::LeftParen, "Expected '(' after COUNT")?;
            self.consume(&TokenType::Asterisk, "Expected '*' in COUNT(*)")?;
            self.consume(&TokenType::RightParen, "Expected ')' after COUNT(*)")?;
            Ok(SelectClause::Count)
        } else if self.is_aggregation_function() {
            let aggregations = self.aggregation_list()?;
            Ok(SelectClause::Aggregations(aggregations))
        } else {
            let fields = self.field_list()?;
            Ok(SelectClause::Fields(fields))
        }
    }

    /// Parse FROM clause
    /// from_clause = "FROM" data_source
    fn from_clause(&mut self) -> Result<FromClause, ParseError> {
        self.consume(&TokenType::From, "Expected 'FROM'")?;

        match &self.peek().token_type {
            TokenType::Diagnostics => {
                self.advance();
                Ok(FromClause::Diagnostics)
            }
            TokenType::Files => {
                self.advance();
                Ok(FromClause::Files)
            }
            TokenType::History => {
                self.advance();
                Ok(FromClause::History)
            }
            TokenType::Trends => {
                self.advance();
                Ok(FromClause::Trends)
            }
            _ => Err(ParseError::UnexpectedToken {
                expected: "data source (diagnostics, files, history, trends)".to_string(),
                found: self.peek().lexeme.clone(),
                line: self.peek().line,
                column: self.peek().column,
            }),
        }
    }

    /// Parse WHERE clause
    /// where_clause = "WHERE" filter_expression
    fn where_clause(&mut self) -> Result<(Vec<QueryFilter>, Option<TimeRange>), ParseError> {
        let mut filters = Vec::new();
        let mut time_range = None;

        let first_filter = self.filter_expression()?;
        
        match first_filter {
            QueryFilter::TimeRange(tr) => time_range = Some(tr),
            filter => filters.push(filter),
        }

        while self.match_token(&TokenType::And) {
            let filter = self.filter_expression()?;
            match filter {
                QueryFilter::TimeRange(tr) => time_range = Some(tr),
                filter => filters.push(filter),
            }
        }

        Ok((filters, time_range))
    }

    /// Parse a filter expression
    fn filter_expression(&mut self) -> Result<QueryFilter, ParseError> {
        if let TokenType::Identifier(field) = &self.peek().token_type.clone() {
            let field_name = field.clone();
            self.advance();

            match field_name.as_str() {
                "path" => self.path_filter(),
                "severity" => self.severity_filter(),
                "category" => self.category_filter(),
                "message" => self.message_filter(),
                "time" | "timestamp" => self.time_filter(),
                "files" | "file_count" => self.file_count_filter(),
                _ => self.custom_filter(field_name),
            }
        } else if self.match_token(&TokenType::Last) {
            self.relative_time_filter()
        } else {
            Err(ParseError::UnexpectedToken {
                expected: "filter field or 'LAST'".to_string(),
                found: self.peek().lexeme.clone(),
                line: self.peek().line,
                column: self.peek().column,
            })
        }
    }

    /// Parse path filter
    fn path_filter(&mut self) -> Result<QueryFilter, ParseError> {
        let op = self.comparison_operator()?;
        let pattern = self.string_value()?;
        
        let is_regex = op == Comparison::Equal; // Simple heuristic
        
        Ok(QueryFilter::Path(PathFilter {
            pattern,
            is_regex,
        }))
    }

    /// Parse severity filter
    fn severity_filter(&mut self) -> Result<QueryFilter, ParseError> {
        let comparison = self.comparison_operator()?;
        let severity_str = self.string_or_identifier()?;
        
        let severity = match severity_str.to_lowercase().as_str() {
            "error" => DiagnosticSeverity::Error,
            "warning" => DiagnosticSeverity::Warning,
            "info" | "information" => DiagnosticSeverity::Information,
            "hint" => DiagnosticSeverity::Hint,
            _ => return Err(ParseError::UnexpectedToken {
                expected: "severity level (error, warning, info, hint)".to_string(),
                found: severity_str,
                line: self.previous().line,
                column: self.previous().column,
            }),
        };

        Ok(QueryFilter::Severity(SeverityFilter {
            severity,
            comparison,
        }))
    }

    /// Parse category filter
    fn category_filter(&mut self) -> Result<QueryFilter, ParseError> {
        self.consume(&TokenType::In, "Expected 'IN' for category filter")?;
        self.consume(&TokenType::LeftParen, "Expected '(' after IN")?;
        
        let mut categories = Vec::new();
        
        loop {
            categories.push(self.string_value()?);
            
            if !self.match_token(&TokenType::Comma) {
                break;
            }
        }
        
        self.consume(&TokenType::RightParen, "Expected ')' after category list")?;
        
        Ok(QueryFilter::Category(CategoryFilter { categories }))
    }

    /// Parse message filter
    fn message_filter(&mut self) -> Result<QueryFilter, ParseError> {
        let op = self.comparison_operator()?;
        let pattern = self.string_value()?;
        
        let is_regex = matches!(op, Comparison::Equal); // Simple heuristic
        
        Ok(QueryFilter::Message(MessageFilter {
            pattern,
            is_regex,
        }))
    }

    /// Parse time filter
    fn time_filter(&mut self) -> Result<QueryFilter, ParseError> {
        let comparison = self.comparison_operator()?;
        
        // Try to parse as ISO timestamp or relative time
        if let TokenType::String(time_str) = &self.peek().token_type.clone() {
            self.advance();
            
            // Try to parse as ISO timestamp
            if let Ok(datetime) = DateTime::<Utc>::from_str(time_str) {
                let time_range = match comparison {
                    Comparison::GreaterThan | Comparison::GreaterThanOrEqual => {
                        TimeRange::absolute(Some(datetime), None)
                    }
                    Comparison::LessThan | Comparison::LessThanOrEqual => {
                        TimeRange::absolute(None, Some(datetime))
                    }
                    _ => TimeRange::absolute(Some(datetime), Some(datetime)),
                };
                
                Ok(QueryFilter::TimeRange(time_range))
            } else {
                Err(ParseError::InvalidTimeFormat {
                    value: time_str.clone(),
                    line: self.previous().line,
                    column: self.previous().column,
                })
            }
        } else {
            Err(ParseError::UnexpectedToken {
                expected: "timestamp string".to_string(),
                found: self.peek().lexeme.clone(),
                line: self.peek().line,
                column: self.peek().column,
            })
        }
    }

    /// Parse file count filter
    fn file_count_filter(&mut self) -> Result<QueryFilter, ParseError> {
        let comparison = self.comparison_operator()?;
        let value = self.number_value()?;
        
        Ok(QueryFilter::FileCount(ComparisonFilter {
            field: "file_count".to_string(),
            comparison,
            value,
        }))
    }

    /// Parse custom filter
    fn custom_filter(&mut self, field: String) -> Result<QueryFilter, ParseError> {
        self.comparison_operator()?; // consume operator
        let value = self.string_or_identifier()?;
        
        Ok(QueryFilter::Custom(field, value))
    }

    /// Parse relative time filter (LAST N DAYS/HOURS/WEEKS)
    fn relative_time_filter(&mut self) -> Result<QueryFilter, ParseError> {
        let value = self.number_value()? as u32;
        
        let relative_time = match &self.peek().token_type {
            TokenType::Hours => {
                self.advance();
                RelativeTime::LastHours(value)
            }
            TokenType::Days => {
                self.advance();
                RelativeTime::LastDays(value)
            }
            TokenType::Weeks => {
                self.advance();
                RelativeTime::LastWeeks(value)
            }
            _ => return Err(ParseError::UnexpectedToken {
                expected: "time unit (hours, days, weeks)".to_string(),
                found: self.peek().lexeme.clone(),
                line: self.peek().line,
                column: self.peek().column,
            }),
        };

        Ok(QueryFilter::TimeRange(TimeRange::relative(relative_time)))
    }

    /// Parse GROUP BY clause
    fn group_by_clause(&mut self) -> Result<GroupByClause, ParseError> {
        // Skip "BY" if present (already consumed "GROUP")
        if self.check(&TokenType::GroupBy) {
            self.advance();
        }
        
        let fields = self.field_list()?;
        Ok(GroupByClause { fields })
    }

    /// Parse ORDER BY clause
    fn order_by_clause(&mut self) -> Result<OrderByClause, ParseError> {
        // Skip "BY" if present (already consumed "ORDER")
        if self.check(&TokenType::OrderBy) {
            self.advance();
        }
        
        let field = self.identifier()?;
        let direction = if self.match_token(&TokenType::Desc) {
            OrderDirection::Descending
        } else {
            self.match_token(&TokenType::Asc); // Optional
            OrderDirection::Ascending
        };
        
        Ok(OrderByClause { field, direction })
    }

    /// Parse LIMIT clause
    fn limit_clause(&mut self) -> Result<usize, ParseError> {
        let value = self.number_value()?;
        Ok(value as usize)
    }

    /// Parse field list
    fn field_list(&mut self) -> Result<Vec<String>, ParseError> {
        let mut fields = Vec::new();
        
        loop {
            fields.push(self.identifier()?);
            
            if !self.match_token(&TokenType::Comma) {
                break;
            }
        }
        
        Ok(fields)
    }

    /// Parse aggregation list
    fn aggregation_list(&mut self) -> Result<Vec<QueryAggregation>, ParseError> {
        let mut aggregations = Vec::new();
        
        loop {
            aggregations.push(self.aggregation_function()?);
            
            if !self.match_token(&TokenType::Comma) {
                break;
            }
        }
        
        Ok(aggregations)
    }

    /// Parse aggregation function
    fn aggregation_function(&mut self) -> Result<QueryAggregation, ParseError> {
        let func_type = self.advance().token_type.clone();
        self.consume(&TokenType::LeftParen, "Expected '(' after aggregation function")?;
        let field = if self.check(&TokenType::Asterisk) {
            self.advance();
            "*".to_string()
        } else {
            self.identifier()?
        };
        self.consume(&TokenType::RightParen, "Expected ')' after aggregation field")?;
        
        match func_type {
            TokenType::Count => Ok(QueryAggregation::Count(field)),
            TokenType::Sum => Ok(QueryAggregation::Sum(field)),
            TokenType::Avg => Ok(QueryAggregation::Average(field)),
            TokenType::Min => Ok(QueryAggregation::Min(field)),
            TokenType::Max => Ok(QueryAggregation::Max(field)),
            _ => Err(ParseError::UnexpectedToken {
                expected: "aggregation function".to_string(),
                found: self.previous().lexeme.clone(),
                line: self.previous().line,
                column: self.previous().column,
            }),
        }
    }

    /// Parse comparison operator
    fn comparison_operator(&mut self) -> Result<Comparison, ParseError> {
        match &self.peek().token_type {
            TokenType::Equal => {
                self.advance();
                Ok(Comparison::Equal)
            }
            TokenType::NotEqual => {
                self.advance();
                Ok(Comparison::NotEqual)
            }
            TokenType::GreaterThan => {
                self.advance();
                Ok(Comparison::GreaterThan)
            }
            TokenType::LessThan => {
                self.advance();
                Ok(Comparison::LessThan)
            }
            TokenType::GreaterThanOrEqual => {
                self.advance();
                Ok(Comparison::GreaterThanOrEqual)
            }
            TokenType::LessThanOrEqual => {
                self.advance();
                Ok(Comparison::LessThanOrEqual)
            }
            _ => Err(ParseError::UnexpectedToken {
                expected: "comparison operator".to_string(),
                found: self.peek().lexeme.clone(),
                line: self.peek().line,
                column: self.peek().column,
            }),
        }
    }

    /// Get string value from token
    fn string_value(&mut self) -> Result<String, ParseError> {
        match &self.peek().token_type {
            TokenType::String(s) => {
                let value = s.clone();
                self.advance();
                Ok(value)
            }
            _ => Err(ParseError::UnexpectedToken {
                expected: "string literal".to_string(),
                found: self.peek().lexeme.clone(),
                line: self.peek().line,
                column: self.peek().column,
            }),
        }
    }

    /// Get number value from token
    fn number_value(&mut self) -> Result<f64, ParseError> {
        match &self.peek().token_type {
            TokenType::Number(n) => {
                let value = *n;
                self.advance();
                Ok(value)
            }
            _ => Err(ParseError::UnexpectedToken {
                expected: "number literal".to_string(),
                found: self.peek().lexeme.clone(),
                line: self.peek().line,
                column: self.peek().column,
            }),
        }
    }

    /// Get string or identifier value
    fn string_or_identifier(&mut self) -> Result<String, ParseError> {
        match &self.peek().token_type {
            TokenType::String(s) => {
                let value = s.clone();
                self.advance();
                Ok(value)
            }
            TokenType::Identifier(id) => {
                let value = id.clone();
                self.advance();
                Ok(value)
            }
            _ => Err(ParseError::UnexpectedToken {
                expected: "string or identifier".to_string(),
                found: self.peek().lexeme.clone(),
                line: self.peek().line,
                column: self.peek().column,
            }),
        }
    }

    /// Get identifier value
    fn identifier(&mut self) -> Result<String, ParseError> {
        match &self.peek().token_type {
            TokenType::Identifier(id) => {
                let value = id.clone();
                self.advance();
                Ok(value)
            }
            _ => Err(ParseError::UnexpectedToken {
                expected: "identifier".to_string(),
                found: self.peek().lexeme.clone(),
                line: self.peek().line,
                column: self.peek().column,
            }),
        }
    }

    /// Check if current token is an aggregation function
    fn is_aggregation_function(&self) -> bool {
        matches!(
            self.peek().token_type,
            TokenType::Count | TokenType::Sum | TokenType::Avg | TokenType::Min | TokenType::Max
        )
    }

    /// Utility methods for token navigation

    fn match_token(&mut self, token_type: &TokenType) -> bool {
        if self.check(token_type) {
            self.advance();
            true
        } else {
            false
        }
    }

    fn check(&self, token_type: &TokenType) -> bool {
        if self.is_at_end() {
            false
        } else {
            std::mem::discriminant(&self.peek().token_type) == std::mem::discriminant(token_type)
        }
    }

    fn advance(&mut self) -> &Token {
        if !self.is_at_end() {
            self.current += 1;
        }
        self.previous()
    }

    fn is_at_end(&self) -> bool {
        self.peek().token_type == TokenType::Eof
    }

    fn peek(&self) -> &Token {
        &self.tokens[self.current]
    }

    fn previous(&self) -> &Token {
        &self.tokens[self.current - 1]
    }

    fn consume(&mut self, token_type: &TokenType, message: &str) -> Result<&Token, ParseError> {
        if self.check(token_type) {
            Ok(self.advance())
        } else {
            Err(ParseError::UnexpectedToken {
                expected: message.to_string(),
                found: self.peek().lexeme.clone(),
                line: self.peek().line,
                column: self.peek().column,
            })
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::query::parser::lexer::Lexer;

    fn parse_query(input: &str) -> Result<Query, ParseError> {
        let mut lexer = Lexer::new(input);
        let tokens = lexer.tokenize()?;
        let mut parser = Parser::new(tokens);
        parser.parse()
    }

    #[test]
    fn test_simple_select_all() {
        let query = parse_query("SELECT * FROM diagnostics").unwrap();
        assert_eq!(query.select, SelectClause::All);
        assert_eq!(query.from, FromClause::Diagnostics);
        assert!(query.filters.is_empty());
    }

    #[test]
    fn test_select_count() {
        let query = parse_query("SELECT COUNT(*) FROM files").unwrap();
        assert_eq!(query.select, SelectClause::Count);
        assert_eq!(query.from, FromClause::Files);
    }

    #[test]
    fn test_select_with_filter() {
        let query = parse_query("SELECT * FROM diagnostics WHERE severity = 'error'").unwrap();
        assert_eq!(query.select, SelectClause::All);
        assert_eq!(query.from, FromClause::Diagnostics);
        assert_eq!(query.filters.len(), 1);
        
        if let QueryFilter::Severity(filter) = &query.filters[0] {
            assert_eq!(filter.severity, DiagnosticSeverity::Error);
        } else {
            panic!("Expected severity filter");
        }
    }

    #[test]
    fn test_relative_time_filter() {
        let query = parse_query("SELECT * FROM diagnostics WHERE LAST 7 DAYS").unwrap();
        assert!(query.time_range.is_some());
        
        if let Some(TimeRange { relative: Some(RelativeTime::LastDays(7)), .. }) = query.time_range {
            // Success
        } else {
            panic!("Expected relative time range");
        }
    }

    #[test]
    fn test_order_by_and_limit() {
        let query = parse_query("SELECT * FROM diagnostics ORDER BY severity DESC LIMIT 10").unwrap();
        assert!(query.order_by.is_some());
        assert_eq!(query.limit, Some(10));
        
        if let Some(order_by) = query.order_by {
            assert_eq!(order_by.field, "severity");
            assert_eq!(order_by.direction, OrderDirection::Descending);
        }
    }
}